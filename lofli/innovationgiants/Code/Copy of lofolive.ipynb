{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lofolive.ipynb","provenance":[{"file_id":"14R5kp9hHm8EkepngAlCDTpWZd7hdQTrq","timestamp":1609748094322},{"file_id":"16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5","timestamp":1609592957469}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8YWs86WD2nD","executionInfo":{"status":"ok","timestamp":1613543281234,"user_tz":-330,"elapsed":20007,"user":{"displayName":"prasad raghavendra","photoUrl":"","userId":"09065291355798302660"}},"outputId":"dbe32a9f-d7f3-44ce-af44-5dee26fe0db9"},"source":["#import os, sys\r\n","#from google.colab import drive\r\n","#drive.mount('/content/mnt')\r\n","#nb_path = '/content/notebooks'\r\n","#os.symlink('/content/mnt/My Drive/colabpackages', nb_path)\r\n","#sys.path.insert(0, nb_path)  # or append(nb_path)\r\n","#https://colab.research.google.com/drive/1KpMDi9CjImudrzXsyTDAuRjtbahzIVjq#scrollTo=trAxoCkMLgF1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/mnt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_FzH13EjseR","executionInfo":{"status":"ok","timestamp":1613543287813,"user_tz":-330,"elapsed":4534,"user":{"displayName":"prasad raghavendra","photoUrl":"","userId":"09065291355798302660"}},"outputId":"02af11bf-bb1e-4c02-a8dc-fa048dfdfd3f"},"source":["# install dependencies: \n","#!pip install pyyaml==5.1\n","#!pip install --target=$nb_path pyyaml==5.1\n","!pip install torch===1.7.1 torchvision===0.8.2 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","#opencv is pre-installed on colab"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.7.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b-i4hmGYk1dL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1613543375577,"user_tz":-330,"elapsed":36237,"user":{"displayName":"prasad raghavendra","photoUrl":"","userId":"09065291355798302660"}},"outputId":"2baf6715-495d-4deb-e0bd-db881b817016"},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","import torch\n","assert torch.__version__.startswith(\"1.7\")\n","\n","#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","#exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime\n","\n","!pip install --target=$nb_path detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","#exit(0)\n","\n","#!pip install --target=$nb_path requests~=2.23.0\n","#!pip install --target=$nb_path  grpcio\n","#!pip install --target=$nb_path  absl-py\n","#!pip install --target=$nb_path  jupyter-client\n","#!pip install --target=$nb_path  imgaug==0.2.7"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","Collecting detectron2\n","\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/detectron2-0.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 5.8MB/s \n","\u001b[?25hCollecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Collecting matplotlib\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/03/b7b30fa81cb687d1178e085d0f01111ceaea3bf81f9330c937fb6f6c8ca0/matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5MB)\n","\u001b[K     |████████████████████████████████| 11.5MB 7.4MB/s \n","\u001b[?25hCollecting pydot\n","  Downloading https://files.pythonhosted.org/packages/ea/76/75b1bb82e9bad3e3d656556eaa353d8cd17c4254393b08ec9786ac8ed273/pydot-1.4.2-py2.py3-none-any.whl\n","Collecting cloudpickle\n","  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n","Collecting pycocotools>=2.0.2\n","  Downloading https://files.pythonhosted.org/packages/de/df/056875d697c45182ed6d2ae21f62015896fdb841906fe48e7268e791c467/pycocotools-2.0.2.tar.gz\n","Collecting termcolor>=1.1\n","  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n","Collecting future\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 52.0MB/s \n","\u001b[?25hCollecting tabulate\n","  Downloading https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n","Collecting fvcore>=0.1.2\n","  Downloading https://files.pythonhosted.org/packages/93/e4/4b5ecbe673be8ed2701d1ade5882f3595d7e00c23255d9d4577d272b9643/fvcore-0.1.3.post20210213.tar.gz\n","Collecting tqdm>4.29.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/db/dcda019790a8d989b8b0e7290f1c651a0aaef10bbe6af00032155e04858d/tqdm-4.56.2-py2.py3-none-any.whl (72kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n","\u001b[?25hCollecting tensorboard\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 50.8MB/s \n","\u001b[?25hCollecting Pillow>=7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c0/442d9d87e0da00bf856ef6dd4916f84a2d710b5f1a367d42d7f3c4e99a6c/Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 48.2MB/s \n","\u001b[?25hCollecting PyYAML\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n","\u001b[K     |████████████████████████████████| 645kB 47.2MB/s \n","\u001b[?25hCollecting kiwisolver>=1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 49.6MB/s \n","\u001b[?25hCollecting cycler>=0.10\n","  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n","Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl (67kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n","\u001b[?25hCollecting numpy>=1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8MB)\n","\u001b[K     |████████████████████████████████| 14.8MB 216kB/s \n","\u001b[?25hCollecting python-dateutil>=2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n","\u001b[K     |████████████████████████████████| 235kB 53.5MB/s \n","\u001b[?25hCollecting setuptools>=18.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/0e/255e3d57965f318973e417d5b7034223f1223de500d91b945ddfaef42a37/setuptools-53.0.0-py3-none-any.whl (784kB)\n","\u001b[K     |████████████████████████████████| 788kB 43.1MB/s \n","\u001b[?25hCollecting cython>=0.27.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/49/91ebe4a00bf894d08dd9680cd9dfb05936eb2848eebd9402b43885aa74cf/Cython-0.29.21-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 43.4MB/s \n","\u001b[?25hCollecting iopath>=0.1.2\n","  Downloading https://files.pythonhosted.org/packages/f2/c8/1830019bcecf26e76c3fdc36e2a6fa454388a233894dcf6f5eb00a881468/iopath-0.1.3.tar.gz\n","Collecting google-auth<2,>=1.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/78/d15c9579274d5d06f11e351edfdac36c4e09d42550f5de083b4b77155421/google_auth-1.26.1-py2.py3-none-any.whl (116kB)\n","\u001b[K     |████████████████████████████████| 122kB 49.7MB/s \n","\u001b[?25hCollecting absl-py>=0.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 54.9MB/s \n","\u001b[?25hCollecting wheel>=0.26; python_version >= \"3\"\n","  Downloading https://files.pythonhosted.org/packages/65/63/39d04c74222770ed1589c0eaba06c05891801219272420b40311cd60c880/wheel-0.36.2-py2.py3-none-any.whl\n","Collecting requests<3,>=2.21.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading https://files.pythonhosted.org/packages/81/67/e2c34bb0628984c7ce71cce6ba6964cb29c418873847fc285f826e032e6e/google_auth_oauthlib-0.4.2-py2.py3-none-any.whl\n","Collecting markdown>=2.6.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/c1/499e600ba0c618b451cd9c425ae1c177249940a2086316552fee7d86c954/tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781kB)\n","\u001b[K     |████████████████████████████████| 788kB 44.0MB/s \n","\u001b[?25hCollecting werkzeug>=0.11.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n","\u001b[K     |████████████████████████████████| 307kB 50.3MB/s \n","\u001b[?25hCollecting grpcio>=1.24.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/55/357022b111b856cadaf63d718d79861fc6215b848eff38b2fbfb9d5c47bd/grpcio-1.35.0-cp36-cp36m-manylinux2014_x86_64.whl (4.1MB)\n","\u001b[K     |████████████████████████████████| 4.1MB 40.8MB/s \n","\u001b[?25hCollecting protobuf>=3.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 41.4MB/s \n","\u001b[?25hCollecting six>=1.10.0\n","  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/82/22/e684c9e2e59b561dbe36538852e81849122c666c423448e3a5c99362c228/portalocker-2.2.1-py2.py3-none-any.whl\n","Collecting cachetools<5.0,>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/bb/72/8df2e0dc991f1a1d2c6869404e7622e8ee50d80bff357dbb57c3df70305b/cachetools-4.2.1-py3-none-any.whl\n","Collecting pyasn1-modules>=0.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n","\u001b[K     |████████████████████████████████| 163kB 52.3MB/s \n","\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n","  Downloading https://files.pythonhosted.org/packages/a0/c6/f6f92e055213860a39c98e51a10a51af473bc799a889fe8edac11108245b/rsa-4.7.1-py3-none-any.whl\n","Collecting certifi>=2017.4.17\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/a0/5f06e1e1d463903cf0c0eebeb751791119ed7a4b3737fdc9a77f1cdfb51f/certifi-2020.12.5-py2.py3-none-any.whl (147kB)\n","\u001b[K     |████████████████████████████████| 153kB 52.0MB/s \n","\u001b[?25hCollecting chardet<5,>=3.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl (178kB)\n","\u001b[K     |████████████████████████████████| 184kB 53.5MB/s \n","\u001b[?25hCollecting idna<3,>=2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/fc/8a49991f7905261f9ca9df5aa9b58363c3c821ce3e7f671895442b7100f2/urllib3-1.26.3-py2.py3-none-any.whl (137kB)\n","\u001b[K     |████████████████████████████████| 143kB 51.7MB/s \n","\u001b[?25hCollecting requests-oauthlib>=0.7.0\n","  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n","Collecting importlib-metadata; python_version < \"3.8\"\n","  Downloading https://files.pythonhosted.org/packages/f3/ed/da40116a204abb5c4dd1d929346d33e0d29cedb2cedd18ea98f0385dcd92/importlib_metadata-3.4.0-py3-none-any.whl\n","Collecting pyasn1<0.5.0,>=0.4.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n","\u001b[?25hCollecting oauthlib>=3.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n","\u001b[K     |████████████████████████████████| 153kB 49.9MB/s \n","\u001b[?25hCollecting zipp>=0.5\n","  Downloading https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n","Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n","  Downloading https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n","Building wheels for collected packages: pycocotools, termcolor, future, fvcore, iopath\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp36-cp36m-linux_x86_64.whl size=265635 sha256=d179d2b101608ec590c551a0d342330ec92bde0003e7af79432d4f709e56e12f\n","  Stored in directory: /root/.cache/pip/wheels/68/a5/e7/56401832f23d0b2db351c5b682e466cb4841960b086da65e4e\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4830 sha256=894301dda134876ac72b786bc792ee14a8336ee0e1b6e42f77920a59b8014c2e\n","  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=a4de6e5df6d2c23485f4b28b7efc2975113d0767f5e9b4f992c182bb2b5a52d1\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.3.post20210213-cp36-none-any.whl size=44977 sha256=dfc1f8d0003abbd4aa01707ee8d1aa4dc4750039c7cfb42e966dc0219c17b237\n","  Stored in directory: /root/.cache/pip/wheels/6e/13/17/51fc28081c91c309faaedf03bf2077a004d887fb66156c45e3\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.3-cp36-none-any.whl size=11169 sha256=b262259220dc0cf91744268d7fb080918dc56a78b8f88761d12651c7c0179ceb\n","  Stored in directory: /root/.cache/pip/wheels/a9/1d/55/94a55e032409ac7617f9cbb88a0fa2cf4e7208806c29730804\n","Successfully built pycocotools termcolor future fvcore iopath\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.35.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-metadata 0.27.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbclient 0.5.2 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: PyYAML, yacs, kiwisolver, six, cycler, pyparsing, Pillow, numpy, python-dateutil, matplotlib, pydot, cloudpickle, setuptools, cython, pycocotools, termcolor, future, tabulate, tqdm, portalocker, iopath, fvcore, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, absl-py, wheel, certifi, chardet, idna, urllib3, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, zipp, typing-extensions, importlib-metadata, markdown, tensorboard-plugin-wit, werkzeug, grpcio, protobuf, tensorboard, detectron2\n","Successfully installed Pillow-8.1.0 PyYAML-5.4.1 absl-py-0.11.0 cachetools-4.2.1 certifi-2020.12.5 chardet-4.0.0 cloudpickle-1.6.0 cycler-0.10.0 cython-0.29.21 detectron2-0.3+cu101 future-0.18.2 fvcore-0.1.3.post20210213 google-auth-1.26.1 google-auth-oauthlib-0.4.2 grpcio-1.35.0 idna-2.10 importlib-metadata-3.4.0 iopath-0.1.3 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.3.4 numpy-1.19.5 oauthlib-3.1.0 portalocker-2.2.1 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.2 pydot-1.4.2 pyparsing-2.4.7 python-dateutil-2.8.1 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.1 setuptools-53.0.0 six-1.15.0 tabulate-0.8.7 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 termcolor-1.1.0 tqdm-4.56.2 typing-extensions-3.7.4.3 urllib3-1.26.3 werkzeug-1.0.1 wheel-0.36.2 yacs-0.1.8 zipp-3.4.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cycler","dateutil","kiwisolver","numpy","pkg_resources","pyparsing","six","typing_extensions"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ZyAvNCJMmvFF","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1613543312270,"user_tz":-330,"elapsed":919,"user":{"displayName":"prasad raghavendra","photoUrl":"","userId":"09065291355798302660"}},"outputId":"08bacd07-800f-4d40-edc0-fea1119b3084"},"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","\n","import IPython\n","from google.colab import output\n","from google.colab.patches import cv2_imshow\n","\n","import time\n","import sys\n","\n","from PIL import Image\n","from io import BytesIO\n","import base64\n","import logging\n","import numpy as np\n","\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode"],"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-49cd7c3ebd1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Some basic setup:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Setup detectron2 logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msetup_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"kfxULPS9mP6K"},"source":["cfg = get_cfg()\r\n","# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\r\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\r\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\r\n","# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\r\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\r\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9iZkCifbqWr"},"source":["'''\r\n","## Camera Capture\r\n","Using a webcam to capture images for processing on the runtime.\r\n","Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\r\n","'''\r\n","def take_photo(filename='photo.jpg', quality=0.8):\r\n","  js = Javascript('''\r\n","    async function takePhoto(quality) {\r\n","      const div = document.createElement('div');\r\n","      const video = document.createElement('video');\r\n","      video.style.display = 'block';\r\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\r\n","\r\n","      // show the video in the HTML element\r\n","      document.body.appendChild(div);\r\n","      //Shows the video\r\n","      div.appendChild(video);\r\n","      video.srcObject = stream;\r\n","      await video.play();\r\n","\r\n","      // Resize the output to fit the video element.\r\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\r\n","\r\n","      // prints the logs to cell\r\n","      let jsLog = function(abc) {\r\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\r\n","      }\r\n","\r\n","      // Wait for Capture to be clicked.\r\n","      // await new Promise((resolve) => capture.onclick = resolve);\r\n","\r\n","      for (let i = 0; i < 5; i++) {\r\n","        const canvas = document.createElement('canvas');\r\n","        canvas.width = video.videoWidth;\r\n","        canvas.height = video.videoHeight;\r\n","        canvas.getContext('2d').drawImage(video, 0, 0);\r\n","        img = canvas.toDataURL('image/jpeg', quality);\r\n","\r\n","        // show each captured image\r\n","        //let imgTag = document.createElement('img');\r\n","        //imgTag.src = img;\r\n","        //div.appendChild(imgTag);\r\n","\r\n","        //jsLog(i + \"sending\")\r\n","        // Call a python function and send this image\r\n","        google.colab.kernel.invokeFunction('notebook.run_algo', [img], {});\r\n","        //jsLog(i + \"SENT\")\r\n","\r\n","        // wait for X miliseconds second, before next capture\r\n","        await new Promise(resolve => setTimeout(resolve, 250));\r\n","      }\r\n","      stream.getVideoTracks()[0].stop(); // stop video stream\r\n","    }\r\n","    ''')\r\n","  display(js) # make the provided HTML, part of the cell\r\n","  data = eval_js('takePhoto({})'.format(quality)) # call the takePhoto() JavaScript function"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CHtsB8gnfGf2"},"source":[""]},{"cell_type":"code","metadata":{"id":"35hJRxRF_5_m"},"source":["def data_uri_to_img(uri):\r\n","  \"\"\"convert base64image to numpy array\"\"\"\r\n","  try:\r\n","    image = base64.b64decode(uri.split(',')[1], validate=True)\r\n","    # make the binary image, a PIL image\r\n","    image = Image.open(BytesIO(image))\r\n","    # convert to numpy array\r\n","    image = np.array(image, dtype=np.uint8); \r\n","    return image\r\n","  except Exception as e:\r\n","    logging.exception(e);print('\\n')\r\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcptQbOpFTjI","colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"status":"ok","timestamp":1613543115998,"user_tz":-330,"elapsed":12754,"user":{"displayName":"prasad raghavendra","photoUrl":"","userId":"09065291355798302660"}},"outputId":"bcda77d1-2722-4e67-a88a-7eaaf2585e7e"},"source":["def run_algo(imgB64):\r\n","  \"\"\"\r\n","  in Colab, run_algo function gets invoked by the JavaScript, that sends N images every second\r\n","\r\n","  params:\r\n","    image: image\r\n","  \"\"\"\r\n","  image = data_uri_to_img(imgB64)  \r\n","  if image is None:\r\n","    print(\"At run_algo(): image is None.\")\r\n","    return\r\n","\r\n","  try:\r\n","    outputs = predictor(image)\r\n","    # look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\r\n","    #print(outputs[\"instances\"].pred_classes)\r\n","    #print(outputs[\"instances\"].pred_boxes)\r\n","\r\n","    # We can use `Visualizer` to draw the predictions on the image.\r\n","    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\r\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n","    cv2_imshow(out.get_image()[:, :, ::-1])\r\n","\r\n","  except Exception as e:\r\n","    logging.exception(e)\r\n","    print('\\n')\r\n","\r\n","# register this function, so JS code could call this\r\n","output.register_callback('notebook.run_algo', run_algo)\r\n","\r\n","# put the JS code in cell and run it\r\n","take_photo()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      // show the video in the HTML element\n","      document.body.appendChild(div);\n","      //Shows the video\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // prints the logs to cell\n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // Wait for Capture to be clicked.\n","      // await new Promise((resolve) => capture.onclick = resolve);\n","\n","      for (let i = 0; i < 5; i++) {\n","        const canvas = document.createElement('canvas');\n","        canvas.width = video.videoWidth;\n","        canvas.height = video.videoHeight;\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // show each captured image\n","        //let imgTag = document.createElement('img');\n","        //imgTag.src = img;\n","        //div.appendChild(imgTag);\n","\n","        //jsLog(i + \"sending\")\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_algo', [img], {});\n","        //jsLog(i + \"SENT\")\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));\n","      }\n","      stream.getVideoTracks()[0].stop(); // stop video stream\n","    }\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"CVP_hitlk2t3"},"source":["#Facial Tagging module"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAC8NCbVmQo4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"194315ec-89f5-4001-f707-1a8649e1125f"},"source":["#!pip install --target=$nb_path face-recognition"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting face-recognition\n","  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n","Collecting dlib>=19.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/2c/ef681c1c717ace11040f9e99fe22dafc843cdd6085eb6120e7ab2a5c662b/dlib-19.21.1.tar.gz (3.6MB)\n","\u001b[K     |████████████████████████████████| 3.6MB 13.0MB/s \n","\u001b[?25hCollecting Click>=6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.2MB/s \n","\u001b[?25hCollecting numpy\n","  Using cached https://files.pythonhosted.org/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl\n","Collecting face-recognition-models>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n","\u001b[K     |████████████████████████████████| 100.2MB 126kB/s \n","\u001b[?25hCollecting Pillow\n","  Using cached https://files.pythonhosted.org/packages/b6/c0/442d9d87e0da00bf856ef6dd4916f84a2d710b5f1a367d42d7f3c4e99a6c/Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl\n","Building wheels for collected packages: dlib, face-recognition-models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vD5ZzjuOmU4_"},"source":["import face_recognition\r\n","import cv2\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zl0J6id8mV1F"},"source":["# Load a sample picture and learn how to recognize it.\r\n","prasad_image = face_recognition.load_image_file(\"/content/mnt/My Drive/colabpackages/prasad.jpg\")\r\n","prasad_face_encoding = face_recognition.face_encodings(prasad_image)[0]\r\n","\r\n","# Load a second sample picture and learn how to recognize it.\r\n","shanaya_image = face_recognition.load_image_file(\"/content/mnt/My Drive/colabpackages/shanaya1.jpg\")\r\n","shanaya_face_encoding = face_recognition.face_encodings(shanaya_image)[0]\r\n","\r\n","# Create arrays of known face encodings and their names\r\n","known_face_encodings = [\r\n","   prasad_face_encoding,\r\n","   shanaya_face_encoding\r\n","]\r\n","known_face_names = [\r\n","    \"RP\",\r\n","    \"Shanaya\"\r\n","]\r\n","\r\n","# Initialize some variables\r\n","face_locations = []\r\n","face_encodings = []\r\n","face_names = []\r\n","process_this_frame = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7CYuGJ9mZ6j"},"source":["'''\r\n","## Camera Capture\r\n","Using a webcam to capture images for processing on the runtime.\r\n","Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\r\n","'''\r\n","#process_this_frame = True\r\n","\r\n","def stream_camera(filename='photo.jpg', quality=0.8):\r\n","  js = Javascript('''\r\n","    async function streamCamera(quality) {\r\n","      const div = document.createElement('div');\r\n","      const video = document.createElement('video');\r\n","      video.style.display = 'block';\r\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\r\n","\r\n","      // show the video in the HTML element\r\n","      document.body.appendChild(div);\r\n","      //Shows the video\r\n","      //div.appendChild(video);\r\n","      video.srcObject = stream;\r\n","      await video.play();\r\n","\r\n","      // Resize the output to fit the video element.\r\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\r\n","\r\n","      // prints the logs to cell\r\n","      let jsLog = function(abc) {\r\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\r\n","      }\r\n","\r\n","      // Wait for Capture to be clicked.\r\n","      // await new Promise((resolve) => capture.onclick = resolve);\r\n","\r\n","      for (let i = 0; i < 3; i++) {\r\n","        const canvas = document.createElement('canvas');\r\n","        canvas.width = video.videoWidth;\r\n","        canvas.height = video.videoHeight;\r\n","        canvas.getContext('2d').drawImage(video, 0, 0);\r\n","        img = canvas.toDataURL('image/jpeg', quality);\r\n","\r\n","        // show each captured image\r\n","        //let imgTag = document.createElement('img');\r\n","        //imgTag.src = img;\r\n","        //div.appendChild(imgTag);\r\n","\r\n","        //jsLog(i + \"sending\")\r\n","        // Call a python function and send this image\r\n","        google.colab.kernel.invokeFunction('notebook.face_algo', [img], {});\r\n","        //jsLog(i + \"SENT\")\r\n","\r\n","        // wait for X miliseconds second, before next capture\r\n","        await new Promise(resolve => setTimeout(resolve, 250));\r\n","      }\r\n","      \r\n","      stream.getVideoTracks()[0].stop(); // stop video stream\r\n","    }\r\n","    ''')\r\n","  display(js) # make the provided HTML, part of the cell\r\n","  data = eval_js('streamCamera({})'.format(quality)) # call the streamCamera() JavaScript function"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uski0a5GmZoL"},"source":[""]},{"cell_type":"code","metadata":{"id":"g75NuEyhmcYF"},"source":["def face_algo(imgB64):\r\n","  frame = data_uri_to_img(imgB64) \r\n","  \r\n","  if frame is None:\r\n","    print(\"At face_algo(): image is None.\")\r\n","    return\r\n","  try:\r\n","    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\r\n","    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\r\n","    rgb_small_frame = small_frame[:, :, ::-1]\r\n","    # Only process every other frame of video to save time\r\n","    #if process_this_frame:\r\n","    # Find all the faces and face encodings in the current frame of video\r\n","    face_locations = face_recognition.face_locations(rgb_small_frame)\r\n","    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\r\n","    face_names = []\r\n","\r\n","    for face_encoding in face_encodings:\r\n","        # See if the face is a match for the known face(s)\r\n","        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\r\n","        name = \"Unknown\"\r\n","\r\n","        # # If a match was found in known_face_encodings, just use the first one.\r\n","        # if True in matches:\r\n","        #     first_match_index = matches.index(True)\r\n","        #     name = known_face_names[first_match_index]\r\n","\r\n","        # Or instead, use the known face with the smallest distance to the new face\r\n","        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\r\n","        best_match_index = np.argmin(face_distances)\r\n","        if matches[best_match_index]:\r\n","            name = known_face_names[best_match_index]\r\n","\r\n","        face_names.append(name)\r\n","\r\n","    #process_this_frame = not process_this_frame\r\n","\r\n","    # Display the results\r\n","    for (top, right, bottom, left), name in zip(face_locations, face_names):\r\n","        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\r\n","        top *= 4\r\n","        right *= 4\r\n","        bottom *= 4\r\n","        left *= 4\r\n","\r\n","        # Blue color in BGR \r\n","        color = (255, 0, 0) \r\n","        # Line thickness of 2 px \r\n","        thickness = 2\r\n","\r\n","        # Draw a box around the face\r\n","        cv2.rectangle(frame, (left, top), (right, bottom), (0,128,0), thickness)\r\n","     \r\n","        # Draw a label with a name below the face\r\n","        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\r\n","        font = cv2.FONT_HERSHEY_DUPLEX\r\n","        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\r\n","\r\n","    # Display the resulting image  \r\n","    cv2_imshow(frame)\r\n","\r\n","  except Exception as e:\r\n","    logging.exception(e)\r\n","    print('\\n')\r\n","  \r\n","# register this function, so JS code could call this\r\n","output.register_callback('notebook.face_algo', face_algo)\r\n","# put the JS code in cell and run it\r\n","stream_camera()"],"execution_count":null,"outputs":[]}]}